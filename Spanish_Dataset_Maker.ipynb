{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Coque24/myapi/blob/main/Spanish_Dataset_Maker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmCPmqFL6hCQ"
      },
      "source": [
        "# üìä Preparador de Lora de Hollowstrawberry\n",
        "\n",
        "Basado en el trabajo de [Kohya_ss](https://github.com/kohya-ss/sd-scripts) y [Linaqruf](https://colab.research.google.com/github/Linaqruf/kohya-trainer/blob/main/kohya-LoRA-dreambooth.ipynb#scrollTo=-Z4w3lfFKLjr). ¬°Gracias!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDoUi4JM_lz9"
      },
      "source": [
        "### ‚≠ï Disclaimer\n",
        "The purpose of this document is to research bleeding-edge technologies in the field of machine learning.  \n",
        "Please read and follow the [Google Colab guidelines](https://research.google.com/colaboratory/faq.html) and its [Terms of Service](https://research.google.com/colaboratory/tos_v3.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BJTp5PVN_q-"
      },
      "source": [
        "| |GitHub|üá¨üáß English|üá™üá∏ Spanish|\n",
        "|:--|:-:|:-:|:-:|\n",
        "| üè† **Origen** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab) | | |\n",
        "| üìä **Dataset Maker** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Dataset_Maker.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Dataset_Maker.ipynb) |\n",
        "| ‚≠ê **Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer.ipynb) | [![Abrir en Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge-spanish.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) |\n",
        "| üåü **XL Lora Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL.ipynb) |  |\n",
        "| üåü **Legacy XL Trainer** | [![GitHub](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/github.svg)](https://github.com/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) | [![Open in Colab](https://raw.githubusercontent.com/hollowstrawberry/kohya-colab/main/assets/colab-badge.svg)](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Lora_Trainer_XL_Legacy.ipynb) |  |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "cBa7KdewQ4BU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4379a99-035b-4774-ef6d-d56628834334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ¬°Proyecto RobloxFaces listo!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "COLAB = True\n",
        "\n",
        "if COLAB:\n",
        "  from google.colab.output import clear as clear_output\n",
        "else:\n",
        "  from IPython.display import clear_output\n",
        "\n",
        "#@title ## üö© Empezar aqu√≠\n",
        "\n",
        "#@markdown ### 1Ô∏è‚É£  Inicio\n",
        "#@markdown Esta celda cargar√° algunos requerimientos y crear√° las carpetas correspondientes en tu Google Drive. <p>\n",
        "#@markdown Tu nombre de proyecto ser√° la carpeta donde trabajaremos. No se permiten espacios.\n",
        "nombre_proyecto = \"RobloxFaces\" #@param {type:\"string\"}\n",
        "project_name = nombre_proyecto.strip()\n",
        "#@markdown La estructura de carpetas no importa y es por comodidad. Aseg√∫rate de siempre elegir la misma. Me gusta organizar por proyecto.\n",
        "estructura_de_carpetas = \"Organizar por proyecto (MyDrive/Loras/nombre_proyecto/dataset)\" #@param [\"Organizar por categor√≠a (MyDrive/lora_training/datasets/nombre_proyecto)\", \"Organizar por proyecto (MyDrive/Loras/nombre_proyecto/dataset)\"]\n",
        "folder_structure = estructura_de_carpetas\n",
        "\n",
        "if not project_name or any(c in project_name for c in \" .()\\\"'\\\\\") or project_name.count(\"/\") > 1:\n",
        "  print(\"Por favor elige un nombre v√°lido.\")\n",
        "else:\n",
        "  if COLAB and not os.path.exists('/content/drive'):\n",
        "    from google.colab import drive\n",
        "    print(\"üìÇ Conectando a Google Drive...\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "  project_base = project_name if \"/\" not in project_name else project_name[:project_name.rfind(\"/\")]\n",
        "  project_subfolder = project_name if \"/\" not in project_name else project_name[project_name.rfind(\"/\")+1:]\n",
        "\n",
        "  root_dir = \"/content\" if COLAB else \"~/Loras\"\n",
        "  deps_dir = os.path.join(root_dir, \"deps\")\n",
        "\n",
        "  if \"/Loras\" in folder_structure:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/Loras\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, project_base)\n",
        "    images_folder = os.path.join(main_dir, project_base, \"dataset\")\n",
        "    if \"/\" in project_name:\n",
        "      images_folder = os.path.join(images_folder, project_subfolder)\n",
        "  else:\n",
        "    main_dir      = os.path.join(root_dir, \"drive/MyDrive/lora_training\") if COLAB else root_dir\n",
        "    config_folder = os.path.join(main_dir, \"config\", project_name)\n",
        "    images_folder = os.path.join(main_dir, \"datasets\", project_name)\n",
        "\n",
        "  for dir in [main_dir, deps_dir, images_folder, config_folder]:\n",
        "    os.makedirs(dir, exist_ok=True)\n",
        "\n",
        "  print(f\"‚úÖ ¬°Proyecto {project_name} listo!\")\n",
        "  step1_installed_flag = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "afu5dCKTV31E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9987ee5-1cb0-4cad-d141-528aa8a91cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping image download. Please upload your images to: MyDrive/MyDrive/Loras/RobloxFaces/dataset\n"
          ]
        }
      ],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "import json\n",
        "import time\n",
        "from urllib.request import urlopen, Request\n",
        "\n",
        "#@markdown ### 2Ô∏è‚É£ Obtener im√°genes\n",
        "\n",
        "#@markdown Obtendremos im√°genes de la galer√≠a de anime llamada [Gelbooru](https://gelbooru.com/). Las im√°genes se organizan por miles de tags que describen todo acerca de una imagen. <p>\n",
        "#@markdown * Si quieres encontrar y usar tus propias im√°genes, ponlas dentro de la carpeta `Loras/nombre_proyecto/dataset` en tu Google Drive.\n",
        "#@markdown * Si quieres descargar capturas de episodios de anime, existe [este otro colab de otra persona](https://colab.research.google.com/drive/1oBSntB40BKzNmKceXUlkXzujzdQw-Ci7) aunque aquel es m√°s complicado.\n",
        "\n",
        "#@markdown Hasta 1000 im√°genes se descargar√°n en un minuto, no debes abusar de ello. <p>\n",
        "#@markdown Tus tags deben ser relevantes para lo que desees entrenar, y excluir elementos no deseados (el contenido expl√≠cito puede hacer m√°s dif√≠cil el entrenamiento).\n",
        "#@markdown Las palabras van separadas por guionbajos, las tags van separadas por espacios, y usa - para excluir esa tag. Tambi√©n puedes incluir una puntuaci√≥n m√≠nima: `score:>10`\n",
        "tags = \"anime goth happy sad mad annoyed hungry funny smile neutral realistic\" #@param {type:\"string\"}\n",
        "#markdown Si una imagen supera esta resoluci√≥n, se descargar√° una versi√≥n m√°s peque√±a.\n",
        "max_resolution = 3072 #param {type:\"slider\", min:1024, max:8196, step:1024}\n",
        "#markdown Posts with a parent post are often minor variations of the same image.\n",
        "include_posts_with_parent = True #param {type:\"boolean\"}\n",
        "\n",
        "tags = tags.replace(\" \", \"+\")\\\n",
        "           .replace(\"(\", \"%28\")\\\n",
        "           .replace(\")\", \"%29\")\\\n",
        "           .replace(\":\", \"%3a\")\\\n",
        "\n",
        "url = \"https://gelbooru.com/index.php?page=dapi&json=1&s=post&q=index&limit=100&tags={}\".format(tags)\n",
        "user_agent = \"Mozilla/5.0 AppleWebKit/537.36 (KHTML, like Gecko; compatible; Googlebot/2.1; +http://www.google.com/bot.html) Chrome/93.0.4577.83 Safari/537.36\"\n",
        "limit = 100 # hardcoded by gelbooru\n",
        "total_limit = 1000 # you can edit this if you want but I wouldn't recommend it\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "\n",
        "def ubuntu_deps():\n",
        "  print(\"üè≠ Instalando...\\n\")\n",
        "  !apt update\n",
        "  !apt -y install aria2\n",
        "  return not get_ipython().__dict__['user_ns']['_exit_code']\n",
        "\n",
        "if \"step2_installed_flag\" not in globals():\n",
        "  if ubuntu_deps():\n",
        "    clear_output()\n",
        "    step2_installed_flag = True\n",
        "  else:\n",
        "    print(\"‚ùå Error en la instalaci√≥n, intentando continuar...\")\n",
        "\n",
        "def get_json(url):\n",
        "  with urlopen(Request(url, headers={\"User-Agent\": user_agent})) as page:\n",
        "    return json.load(page)\n",
        "\n",
        "def filter_images(data):\n",
        "  return [p[\"file_url\"] if p[\"width\"]*p[\"height\"] <= max_resolution**2 else p[\"sample_url\"]\n",
        "          for p in data[\"post\"]\n",
        "          if (p[\"parent_id\"] == 0 or include_posts_with_parent)\n",
        "          and p[\"file_url\"].lower().endswith(supported_types)]\n",
        "\n",
        "def download_images():\n",
        "  data = get_json(url)\n",
        "  count = data[\"@attributes\"][\"count\"]\n",
        "\n",
        "  if count == 0:\n",
        "    print(\"üì∑ No se encontraron resultados.\")\n",
        "    return\n",
        "\n",
        "  print(f\"üéØ Se encontraron {count} resultados\")\n",
        "  test_url = \"https://gelbooru.com/index.php?page=post&s=list&tags={}\".format(tags)\n",
        "  display(Markdown(f\"[¬°Click aqu√≠ para verlos en tu navegador!]({test_url})\"))\n",
        "  print (f\"üîΩ Se descargar√° en {images_folder.replace('/content/drive/', '')} (Aparecer√° una confirmaci√≥n aqu√≠ abajo, sino vuelve a correr esta celda)\")\n",
        "  inp = input(\"‚ùì Escribe \\\"si\\\" para continuar con la descarga: \")\n",
        "\n",
        "  if inp.lower().strip() not in (\"si\", \"s√≠\"):\n",
        "    print(\"‚ùå Download cancelled\")\n",
        "    return\n",
        "\n",
        "  print(\"üì© Obteniendo lista de im√°genes...\")\n",
        "\n",
        "  image_urls = set()\n",
        "  image_urls = image_urls.union(filter_images(data))\n",
        "  for i in range(total_limit // limit):\n",
        "    count -= limit\n",
        "    if count <= 0:\n",
        "      break\n",
        "    time.sleep(0.1)\n",
        "    image_urls = image_urls.union(filter_images(get_json(url+f\"&pid={i+1}\")))\n",
        "\n",
        "  scrape_file = os.path.join(config_folder, f\"scrape_{project_subfolder}.txt\")\n",
        "  with open(scrape_file, \"w\") as f:\n",
        "    f.write(\"\\n\".join(image_urls))\n",
        "\n",
        "  print(f\"üåê Enlaces guardados a {scrape_file}\\n\\nüîÅ Descargando im√°genes ...\\n\")\n",
        "  old_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "\n",
        "  os.chdir(images_folder)\n",
        "  !aria2c --console-log-level=warn -c -x 16 -k 1M -s 16 -i {scrape_file}\n",
        "\n",
        "  new_img_count = len([f for f in os.listdir(images_folder) if f.lower().endswith(supported_types)])\n",
        "  print(f\"\\n‚úÖ Se han descargado {new_img_count - old_img_count} im√°genes.\")\n",
        "\n",
        "# download_images()\n",
        "print(f\"Skipping image download. Please upload your images to: {images_folder.replace('/content/drive/', 'MyDrive/')}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X1A52Ujph0HX",
        "outputId": "ede0c3ef-9be4-4f84-9f16-4d82aef688fd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "b218DEEMpwzB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 653
        },
        "outputId": "7e12f9da-4266-4ab0-bb4d-ad62c4ec5bc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/glob2/fnmatch.py:141: SyntaxWarning: invalid escape sequence '\\Z'\n",
            "  return '(?ms)' + res + '\\Z'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíø Analizando dataset...\n",
            "\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fiftyone.core.odm.database:You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [41.5ms elapsed, 0s remaining, 1.9K samples/s]   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 80/80 [41.5ms elapsed, 0s remaining, 1.9K samples/s]   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model from 'https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.core.models:Downloading model from 'https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    2.6Gb/2.6Gb [5.2s elapsed, 0s remaining, 260.7Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà|    2.6Gb/2.6Gb [5.2s elapsed, 0s remaining, 260.7Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CLIP tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.clip.zoo:Downloading CLIP tokenizer...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "WebSessionError",
          "evalue": "Unable to get 'https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mWebSessionError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-632304708.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageDirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m\"duplicados\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfoz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_zoo_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/zoo/models/__init__.py\u001b[0m in \u001b[0;36mload_zoo_model\u001b[0;34m(name_or_url, model_name, download_if_necessary, ensure_requirements, install_requirements, error_level, cache, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path_in_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/core/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_config_dict, model_path, **kwargs)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0;31m# Build model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/eta/core/learning.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0ma\u001b[0m \u001b[0mModel\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \"\"\"\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_cls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_default_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/utils/clip/zoo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/utils/torch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;31m# Load model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/utils/clip/zoo.py\u001b[0m in \u001b[0;36m_download_model\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_download_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_model_if_necessary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_tokenizer_if_necessary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/fiftyone/utils/clip/zoo.py\u001b[0m in \u001b[0;36mdownload_tokenizer_if_necessary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Downloading CLIP tokenizer...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             etaw.download_file(\n\u001b[0m\u001b[1;32m     70\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer_base_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenizer_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/eta/core/web.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(url, path, chunk_size, verify, quiet)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[1;32m     52\u001b[0m     \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWebSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/eta/core/web.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, path, url, params)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mWebSessionError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdownload\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \"\"\"\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_streaming_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0metau\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_basedir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/eta/core/web.py\u001b[0m in \u001b[0;36m_get_streaming_response\u001b[0;34m(self, url, headers, params)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m206\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mWebSessionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to get '%s'\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mWebSessionError\u001b[0m: Unable to get 'https://github.com/openai/CLIP/raw/main/clip/bpe_simple_vocab_16e6.txt.gz'"
          ]
        }
      ],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Please run step 1 first!\")\n",
        "\n",
        "#@markdown ### 3Ô∏è‚É£ Filtrar tus im√°genes\n",
        "#@markdown Vamos a detectar y borrar im√°genes duplicadas usando la IA de FiftyOne. <p>\n",
        "#@markdown Porcentaje de similaridad para que dos im√°genes se consideren iguales. Recomiendo 0.97 to 0.99:\n",
        "similaridad = 0.985 #@param {type:\"number\"}\n",
        "similarity_threshold = similaridad\n",
        "#@markdown Puedes elegir entre simplemente borrar los duplicados, o adicionalmente abrir un √°rea interactiva bajo esta celda para visualizar tus im√°genes y marcar las que quieras con `delete` que luego ser√°n borradas. <p>\n",
        "#@markdown Si el √°rea interactiva no aparece o est√° vac√≠a, intenta activar las cookies y quitar la protecci√≥n contra rastreo para la p√°gina de Google Colab en tu navegador.\n",
        "#@markdown Para guardar los cambios del √°rea interactiva tendr√°s que apretar Enter en la caja de texto que aparecer√° sobre el area interactiva.<p>\n",
        "accion = \"Borrar duplicados\" #@param [\"Borrar duplicados\",\"Marcar duplicados y abrir area interactiva\",\"Abrir area interactiva\"]\n",
        "action = accion\n",
        "\n",
        "open_in_new_tab = False\n",
        "ngrok_token = \"\"\n",
        "\n",
        "\n",
        "os.chdir(root_dir)\n",
        "model_name = \"clip-vit-base32-torch\"\n",
        "supported_types = (\".png\", \".jpg\", \".jpeg\")\n",
        "img_count = len(os.listdir(images_folder))\n",
        "batch_size = min(250, img_count)\n",
        "\n",
        "if \"step3_installed_flag\" not in globals():\n",
        "  print(\"üè≠ Instalando dependencias...\\n\")\n",
        "  !pip -q install fiftyone ftfy pyngrok\n",
        "  !pip -q install fiftyone-db-ubuntu2204\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    clear_output()\n",
        "    step3_installed_flag = True\n",
        "  else:\n",
        "    print(\"‚ùå Error de instalaci√≥n, intentando continuar de todas formas...\")\n",
        "\n",
        "os.environ[\"FIFTYONE_SERVER\"] = \"0\"\n",
        "import numpy as np\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from pyngrok import ngrok, conf\n",
        "from portpicker import pick_unused_port\n",
        "\n",
        "non_images = [f for f in os.listdir(images_folder) if not f.lower().endswith(supported_types)]\n",
        "if non_images:\n",
        "  print(f\"üí• Error: El archivo {non_images[0]} no es una imagen - Esto no est√° permitido. Usa los Extras m√°s abajo para borrar los archivos que no sean im√°genes.\")\n",
        "elif img_count == 0:\n",
        "  print(f\"üí• Error: No se encontraron im√°genes en {images_folder}\")\n",
        "else:\n",
        "  print(\"\\nüíø Analizando dataset...\\n\")\n",
        "  dataset = fo.Dataset.from_dir(images_folder, dataset_type=fo.types.ImageDirectory)\n",
        "  if \"duplicados\" in action:\n",
        "    model = foz.load_zoo_model(model_name)\n",
        "    embeddings = dataset.compute_embeddings(model, batch_size=batch_size)\n",
        "\n",
        "    batch_embeddings = np.array_split(embeddings, batch_size)\n",
        "    similarity_matrices = []\n",
        "    max_size_x = max(array.shape[0] for array in batch_embeddings)\n",
        "    max_size_y = max(array.shape[1] for array in batch_embeddings)\n",
        "\n",
        "    for i, batch_embedding in enumerate(batch_embeddings):\n",
        "      similarity = cosine_similarity(batch_embedding)\n",
        "      #Pad 0 for np.concatenate\n",
        "      padded_array = np.zeros((max_size_x, max_size_y))\n",
        "      padded_array[0:similarity.shape[0], 0:similarity.shape[1]] = similarity\n",
        "      similarity_matrices.append(padded_array)\n",
        "\n",
        "    similarity_matrix = np.concatenate(similarity_matrices, axis=0)\n",
        "    similarity_matrix = similarity_matrix[0:embeddings.shape[0], 0:embeddings.shape[0]]\n",
        "\n",
        "    similarity_matrix = cosine_similarity(embeddings)\n",
        "    similarity_matrix -= np.identity(len(similarity_matrix))\n",
        "\n",
        "    dataset.match(F(\"max_similarity\") > similarity_threshold)\n",
        "    dataset.tags = [\"delete\", \"has_duplicates\"]\n",
        "\n",
        "    id_map = [s.id for s in dataset.select_fields([\"id\"])]\n",
        "    samples_to_remove = set()\n",
        "    samples_to_keep = set()\n",
        "\n",
        "    for idx, sample in enumerate(dataset):\n",
        "      if sample.id not in samples_to_remove:\n",
        "        # Keep the first instance of two duplicates\n",
        "        samples_to_keep.add(sample.id)\n",
        "\n",
        "        dup_idxs = np.where(similarity_matrix[idx] > similarity_threshold)[0]\n",
        "        for dup in dup_idxs:\n",
        "            # We kept the first instance so remove all other duplicates\n",
        "            samples_to_remove.add(id_map[dup])\n",
        "\n",
        "        if len(dup_idxs) > 0:\n",
        "            sample.tags.append(\"has_duplicates\")\n",
        "            sample.save()\n",
        "      else:\n",
        "        sample.tags.append(\"delete\")\n",
        "        sample.save()\n",
        "\n",
        "    sidebar_groups = fo.DatasetAppConfig.default_sidebar_groups(dataset)\n",
        "    for group in sidebar_groups[1:]:\n",
        "      group.expanded = False\n",
        "    dataset.app_config.sidebar_groups = sidebar_groups\n",
        "    dataset.save()\n",
        "\n",
        "  if \"interactiva\" in action:\n",
        "    clear_output()\n",
        "    os.environ[\"FIFTYONE_SERVER\"] = \"1\"\n",
        "    port = pick_unused_port()\n",
        "    session = fo.launch_app(dataset, port=port, auto=not open_in_new_tab)\n",
        "    if open_in_new_tab:\n",
        "      conf.get_default().auth_token = ngrok_token\n",
        "      public_url = ngrok.connect(port).public_url\n",
        "      print(f\"üü¢ Sesi√≥n abierrta en {public_url}\")\n",
        "\n",
        "    print(\"‚ùó Espera un minuto para que cargue la sesi√≥n, sino, revisa las instrucciones arriba.\")\n",
        "    print(\"‚ùó Cuando est√© listo, ver√°s una cuadr√≠cula con tus im√°genes.\")\n",
        "    print(\"‚ùó A la izquierda puedes activar \\\"sample tags\\\" para ver las im√°genes que est√°n marcadas.\")\n",
        "    print(\"‚ùó Puedes marcar las im√°genes que quieras tras haberlas seleccionado, poniendo un tag llamado \\\"delete\\\" en la parte superior.\")\n",
        "    input(\"‚≠ï Cuando est√©s listo, debes guardar los cambios enviando Enter en esta caja de texto: \")\n",
        "\n",
        "    print(\"üíæ Saving...\")\n",
        "\n",
        "  marked = [s for s in dataset if \"delete\" in s.tags]\n",
        "  dataset.delete_samples(marked)\n",
        "  previous_folder = images_folder[:images_folder.rfind(\"/\")]\n",
        "  dataset.export(export_dir=os.path.join(images_folder, project_subfolder), dataset_type=fo.types.ImageDirectory)\n",
        "\n",
        "  temp_suffix = \"_temp\"\n",
        "  !mv {images_folder} {images_folder}{temp_suffix}\n",
        "  !mv {images_folder}{temp_suffix}/{project_subfolder} {images_folder}\n",
        "  !rm -r {images_folder}{temp_suffix}\n",
        "\n",
        "  if \"interactiva\" in action:\n",
        "    session.refresh()\n",
        "    fo.close_app()\n",
        "    clear_output()\n",
        "\n",
        "  print(f\"\\n‚úÖ {len(marked)} im√°genes han sido borradas. Ahora tienes {len(os.listdir(images_folder))} im√°genes.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "sl4FD7Mz-uea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c648d5-5303-4c1e-f809-424fc81e950e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Tagging finalizado. Aqu√≠ est√°n las 50 im√°genes m√°s comunes en tu dataset:\n",
            "black background (80)\n",
            "simple background (77)\n",
            "no humans (67)\n",
            "solo (57)\n",
            "looking at viewer (40)\n",
            "monochrome (29)\n",
            "eye focus (28)\n",
            "black eyes (27)\n",
            "1girl (24)\n",
            "greyscale (22)\n",
            "close-up (18)\n",
            "dark (15)\n",
            "silhouette (15)\n",
            "eyelashes (15)\n",
            "smile (14)\n",
            "open mouth (13)\n",
            "star (symbol) (11)\n",
            "symbol-shaped pupils (11)\n",
            "blending (11)\n",
            "blush (10)\n",
            "pink-tinted eyewear (10)\n",
            "straight-on (9)\n",
            "red eyes (8)\n",
            "makeup (8)\n",
            "round eyewear (8)\n",
            "tinted eyewear (8)\n",
            "1other (8)\n",
            "star-shaped pupils (7)\n",
            "symbol in eye (7)\n",
            "star in eye (7)\n",
            "staring (6)\n",
            "tongue (6)\n",
            "heart (6)\n",
            "tongue out (5)\n",
            "fang (5)\n",
            "black theme (4)\n",
            "licking lips (4)\n",
            "fangs (4)\n",
            "closed mouth (4)\n",
            "heart-shaped pupils (4)\n",
            "horror (theme) (4)\n",
            "glasses (4)\n",
            "text focus (4)\n",
            "+_+ (4)\n",
            "sparkling eyes (4)\n",
            "grin (4)\n",
            "mole (4)\n",
            "mole under eye (4)\n",
            "darkness (3)\n",
            "still life (3)\n"
          ]
        }
      ],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor corre el paso 1 primero!\")\n",
        "\n",
        "#@markdown ### 4Ô∏è‚É£ Generar descripciones\n",
        "#@markdown Usaremos inteligencia artificial para describir tus im√°genes, espec√≠ficamente [Waifu Diffusion](https://huggingface.co/SmilingWolf/wd-eva02-large-tagger-v3) en el caso de anime (etiquetas/tags) y [BLIP](https://huggingface.co/spaces/Salesforce/BLIP) en el caso de fotograf√≠as (subt√≠tulos/captions) <p>\n",
        "#@markdown Estas descripciones que van junto a tus im√°genes mejoran notablemente la calidad de tu Lora a la hora de entrenar. El proceso demora 5 minutes en instalar y 5 minutos m√°s para describir 1000 im√°genes. Recorre todas las subcarpetas si existen. <p>\n",
        "metodo = \"Tags de Anime\" #@param [\"Tags de Anime\", \"Descripciones de Fotos\"]\n",
        "method = metodo\n",
        "#@markdown **Anime:** Usar ambos taggers es m√°s preciso que uno o el otro. Menor umbral generar√° m√°s tags, prueba 0.25 para conceptos y 0.50 para estilos. Deber√≠as incluir nombres de personajes si no est√°s entrenando un personaje.\n",
        "tagger = \"Ambos\" #@param [\"Ambos\",\"SmilingWolf/wd-eva02-large-tagger-v3\",\"SmilingWolf/wd-vit-large-tagger-v3\"]\n",
        "umbral = 0.5 #@param {type:\"slider\", min:0.0, max:1.0, step:0.01}\n",
        "tag_threshold = umbral\n",
        "tags_no_permitidas = \"virtual youtuber, parody, style parody, official alternate costume, official alternate hairstyle, official alternate hair length, alternate costume, alternate hairstyle, alternate hair length, alternate hair color\" #@param {type:\"string\"}\n",
        "blacklist_tags = tags_no_permitidas\n",
        "nombres_de_personajes = False #@param {type:\"boolean\"}\n",
        "include_character_names = nombres_de_personajes\n",
        "#@markdown **Fotograf√≠as:** El m√≠nmimo y m√°ximo largo de cada subt√≠tulo (medido en tokens/palabras).\n",
        "largo_minimo = 10 #@param {type:\"number\"}\n",
        "caption_min = largo_minimo\n",
        "largo_maximo = 75 #@param {type:\"number\"}\n",
        "caption_max = largo_maximo\n",
        "\n",
        "character_threshold = tag_threshold if include_character_names else 1.1\n",
        "undesired_tags = '\"' + ','.join([t.strip() for t in blacklist_tags.split(\",\") if t.strip()]) + '\"'\n",
        "\n",
        "kohya_dir = \"/content/kohya\"\n",
        "venv_python = os.path.join(kohya_dir, \"venv/bin/python\")\n",
        "venv_pip = os.path.join(kohya_dir, \"venv/bin/pip\")\n",
        "\n",
        "if \"step4_installed_flag\" not in globals():\n",
        "  print(\"\\nüè≠ Instalando dependencias...\\n\")\n",
        "  !apt update\n",
        "  !apt install -y python3.10-venv -qq\n",
        "  !git clone https://github.com/kohya-ss/sd-scripts {kohya_dir}\n",
        "  os.chdir(kohya_dir)\n",
        "  !git reset --hard e89653975ddf429cdf0c0fd268da0a5a3e8dba1f\n",
        "  !python3.10 -m venv venv\n",
        "  !{venv_pip} install -r requirements.txt\n",
        "  !{venv_pip} install fairscale==0.4.13 timm==0.6.12\n",
        "  !{venv_pip} install onnx onnxruntime-gpu==1.20.1 --extra-index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/onnxruntime-cuda-12/pypi/simple/\n",
        "  !{venv_pip} uninstall -y rich\n",
        "  step4_installed_flag = True\n",
        "\n",
        "print(\"\\nüö∂‚Äç‚ôÇÔ∏è Corriendo programa...\\n\")\n",
        "os.chdir(kohya_dir)\n",
        "\n",
        "if \"Anime\" in method:\n",
        "  tagger_models = [\n",
        "    \"SmilingWolf/wd-eva02-large-tagger-v3\",\n",
        "    \"SmilingWolf/wd-vit-large-tagger-v3\"\n",
        "  ] if tagger == \"Ambos\" else [tagger]\n",
        "\n",
        "  for i, tagger_model in enumerate(tagger_models):\n",
        "    append_tags = \"--append_tags\" if i > 0 else \"\"\n",
        "    !{venv_python} finetune/tag_images_by_wd14_tagger.py \\\n",
        "      {images_folder} \\\n",
        "      --repo_id={tagger_model} \\\n",
        "      --general_threshold={tag_threshold} \\\n",
        "      --character_threshold={character_threshold} \\\n",
        "      --batch_size=8 \\\n",
        "      --max_data_loader_n_workers=2 \\\n",
        "      --caption_extension=.txt \\\n",
        "      --undesired_tags {undesired_tags} \\\n",
        "      --onnx --recursive --remove_underscore {append_tags}\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    # Count tags\n",
        "    from collections import Counter\n",
        "    text_files = []\n",
        "    for root, dirs, files in os.walk(images_folder):\n",
        "      for file in files:\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "          text_files.append(os.path.join(root, file))\n",
        "    top_tags = Counter()\n",
        "    for file in text_files:\n",
        "      with open(file, 'r') as f:\n",
        "        tags = [t.strip() for t in f.read().split(\",\")]\n",
        "      top_tags.update(tags)\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"üìä Tagging finalizado. Aqu√≠ est√°n las 50 im√°genes m√°s comunes en tu dataset:\")\n",
        "    print(\"\\n\".join(f\"{k} ({v})\" for k, v in top_tags.most_common(50)))\n",
        "\n",
        "else:\n",
        "  !{venv_python} finetune/make_captions.py \\\n",
        "    {images_folder} \\\n",
        "    --beam_search \\\n",
        "    --max_data_loader_n_workers=2 \\\n",
        "    --batch_size=8 \\\n",
        "    --min_length={caption_min} \\\n",
        "    --max_length={caption_max} \\\n",
        "    --caption_extension=.txt \\\n",
        "    --recursive\n",
        "\n",
        "  if not get_ipython().__dict__['user_ns']['_exit_code']:\n",
        "    import random\n",
        "    for root, dirs, files in os.walk(images_folder):\n",
        "      for file in files:\n",
        "        if file.lower().endswith(\".txt\"):\n",
        "          text_files.append(os.path.join(root, file))\n",
        "    sample = []\n",
        "    for txt in random.sample(captions, min(10, len(captions))):\n",
        "      with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "        sample.append(f.read())\n",
        "\n",
        "    clear_output()\n",
        "    print(f\"üìä Captioning finalizado. Aqu√≠ hay {len(sample)} ejemplos de descripciones en tu dataset:\")\n",
        "    print(\"\".join(sample))\n",
        "\n",
        "os.chdir(root_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WBFik7accyDz"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### 5Ô∏è‚É£ Editar las tags\n",
        "#@markdown Paso opcional para tags de anime. Puedes correr este paso cuantas veces quieras. <p>\n",
        "\n",
        "#@markdown A√±adir una palabra de activaci√≥n a tu Lora, √∫til para mejorar el entrenamiento y usarlo en tus prompts. En el entrenamiento debes poner `keep_tokens` igual a 1.<p>\n",
        "#@markdown Si quitas tags comunes como el color de pelo/ojos √©stas ser√°n \"absorbidas\" por tu palabra de activaci√≥n.\n",
        "palabra_de_activacion = \"\" #@param {type:\"string\"}\n",
        "global_activation_tag = palabra_de_activacion\n",
        "quitar_tags = \"\" #@param {type:\"string\"}\n",
        "remove_tags = quitar_tags\n",
        "#@markdown <p>&nbsp;<p> En esta zona avanzada puedes realizar reemplazos o combinaciones de tags para as√≠ mejorar su calidad. Puedes reemplazar 1 tag por varias, o varias por 1, o una por otra, etc. Tambi√©n puedes a√±adir palabras de activaci√≥n espec√≠ficas.\n",
        "buscar_tags = \"\" #@param {type:\"string\"}\n",
        "search_tags = buscar_tags\n",
        "reemplazar_con = \"\" #@param {type:\"string\"}\n",
        "replace_with = reemplazar_con\n",
        "modo_de_busqueda = \"OR (puede tener cualquiera)\" #@param [\"OR (puede tener cualquiera)\", \"AND (debe tener todo)\"]\n",
        "search_mode = modo_de_busqueda\n",
        "tag_nueva_se_convierte_en_palabra_de_activacion = False #@param {type:\"boolean\"}\n",
        "new_becomes_activation_tag = tag_nueva_se_convierte_en_palabra_de_activacion\n",
        "#@markdown Estas pueden ser √∫tiles a veces. Ten cuidado, pueden quitar las palabras de activaci√≥n previas.\n",
        "ordenar_alfabeticamente = False #@param {type:\"boolean\"}\n",
        "sort_alphabetically = ordenar_alfabeticamente\n",
        "quitar_duplicados = False #@param {type:\"boolean\"}\n",
        "remove_duplicates = quitar_duplicados\n",
        "\n",
        "def split_tags(tagstr):\n",
        "  return [s.strip() for s in tagstr.split(\",\") if s.strip()]\n",
        "\n",
        "activation_tag_list = split_tags(global_activation_tag)\n",
        "remove_tags_list = split_tags(remove_tags)\n",
        "search_tags_list = split_tags(search_tags)\n",
        "replace_with_list = split_tags(replace_with)\n",
        "replace_new_list = [t for t in replace_with_list if t not in search_tags_list]\n",
        "\n",
        "replace_with_list = [t for t in replace_with_list if t not in replace_new_list]\n",
        "replace_new_list.reverse()\n",
        "activation_tag_list.reverse()\n",
        "\n",
        "remove_count = 0\n",
        "replace_count = 0\n",
        "\n",
        "text_files = []\n",
        "for root, dirs, files in os.walk(images_folder):\n",
        "  for file in files:\n",
        "    if file.lower().endswith(\".txt\"):\n",
        "      text_files.append(os.path.join(root, file))\n",
        "\n",
        "for txt in text_files:\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'r') as f:\n",
        "    tags = [s.strip() for s in f.read().split(\",\")]\n",
        "\n",
        "  if remove_duplicates:\n",
        "    tags = list(set(tags))\n",
        "  if sort_alphabetically:\n",
        "    tags.sort()\n",
        "\n",
        "  for rem in remove_tags_list:\n",
        "    if rem in tags:\n",
        "      remove_count += 1\n",
        "      tags.remove(rem)\n",
        "\n",
        "  if \"AND\" in search_mode and all(r in tags for r in search_tags_list) \\\n",
        "      or \"OR\" in search_mode and any(r in tags for r in search_tags_list):\n",
        "    replace_count += 1\n",
        "    for rem in search_tags_list:\n",
        "      if rem in tags:\n",
        "        tags.remove(rem)\n",
        "    for add in replace_with_list:\n",
        "      if add not in tags:\n",
        "        tags.append(add)\n",
        "    for new in replace_new_list:\n",
        "      if new_becomes_activation_tag:\n",
        "        if new in tags:\n",
        "          tags.remove(new)\n",
        "        tags.insert(0, new)\n",
        "      else:\n",
        "        if new not in tags:\n",
        "          tags.append(new)\n",
        "\n",
        "  for act in activation_tag_list:\n",
        "    if act in tags:\n",
        "      tags.remove(act)\n",
        "    tags.insert(0, act)\n",
        "\n",
        "  with open(os.path.join(images_folder, txt), 'w') as f:\n",
        "    f.write(\", \".join(tags))\n",
        "\n",
        "if remove_tags:\n",
        "  print(f\"\\nüöÆ Se han quitado {remove_count} tags.\")\n",
        "if search_tags:\n",
        "  print(f\"\\nüí´ Se han hecho {replace_count} reemplazos.\")\n",
        "print(\"\\n‚úÖ ¬°Listo!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HuJB7BGAyZCw"
      },
      "outputs": [],
      "source": [
        "#@markdown ### 6Ô∏è‚É£  Listo\n",
        "#@markdown Ahora debes estar listo para [entrenar tu Lora](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb).\n",
        "\n",
        "from IPython.display import Markdown, display\n",
        "display(Markdown(f\"ü¶Ä [Click aqu√≠ para abrir el colab de entrenamiento](https://colab.research.google.com/github/hollowstrawberry/kohya-colab/blob/main/Spanish_Lora_Trainer.ipynb) \"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDB9GXRONfiU"
      },
      "source": [
        "## *Ô∏è‚É£ Extras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xEsqOglcc6hA"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üìà Analizar tags\n",
        "#@markdown Volver a ver las tags m√°s comunes en tus im√°genes.\n",
        "ver_top = 50 #@param {type:\"number\"}\n",
        "show_top_tags = ver_top\n",
        "\n",
        "text_files = []\n",
        "for root, dirs, files in os.walk(images_folder):\n",
        "  for file in files:\n",
        "    if file.lower().endswith(\".txt\"):\n",
        "      text_files.append(os.path.join(root, file))\n",
        "\n",
        "from collections import Counter\n",
        "top_tags = Counter()\n",
        "for file in text_files:\n",
        "  with open(file, 'r') as f:\n",
        "    tags = [t.strip() for t in f.read().split(\",\")]\n",
        "  top_tags.update(tags)\n",
        "\n",
        "print(f\"üìä Tus {show_top_tags} tags m√°s comunes:\")\n",
        "for k, v in top_tags.most_common(show_top_tags):\n",
        "  print(f\"{k} ({v})\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hcAHDi3zPjtg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üìÇ Extraer datos\n",
        "#@markdown Es lento subir muchos archivos peque√±os, si quieres puedes subir un zip y extraerlo aqu√≠.\n",
        "zip = \"/content/drive/MyDrive/Loras/warrior.zip\" #@param {type:\"string\"}\n",
        "extract_to = \"/content/drive/MyDrive/Loras/ejemplo/dataset\" #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "  from google.colab import drive\n",
        "  print(\"üìÇ Connecting to Google Drive...\")\n",
        "  drive.mount('/content/drive')\n",
        "\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip, 'r') as f:\n",
        "  f.extractall(extract_to)\n",
        "\n",
        "print(\"‚úÖ Done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7AdGcZRyPmtm"
      },
      "outputs": [],
      "source": [
        "#@markdown ### üî¢ Contar archivos\n",
        "#@markdown Google Drive hace imposible contar los archivos en una carpeta, por lo que aqu√≠ puedes ver la cantidad de archivos en carpetas y subcarpetas.\n",
        "carpeta = \"/content/drive/MyDrive/Loras\" #@param {type:\"string\"}\n",
        "folder = carpeta\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"üìÇ Connecting to Google Drive...\\n\")\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "tree = {}\n",
        "exclude = (\"_logs\", \"/output\")\n",
        "for i, (root, dirs, files) in enumerate(os.walk(folder, topdown=True)):\n",
        "  dirs[:] = [d for d in dirs if all(ex not in d for ex in exclude)]\n",
        "  images = len([f for f in files if f.lower().endswith((\".png\", \".jpg\", \".jpeg\"))])\n",
        "  captions = len([f for f in files if f.lower().endswith(\".txt\")])\n",
        "  others = len(files) - images - captions\n",
        "  path = root[folder.rfind(\"/\")+1:]\n",
        "  tree[path] = None if not images else f\"{images:>4} images | {captions:>4} captions |\"\n",
        "  if tree[path] and others:\n",
        "    tree[path] += f\" {others:>4} other files\"\n",
        "\n",
        "pad = max(len(k) for k in tree)\n",
        "print(\"\\n\".join(f\"üìÅ{k.ljust(pad)} | {v}\" for k, v in tree.items() if v))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "FnN-rD4m_l0L"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Please run step 1 first!\")\n",
        "\n",
        "from PIL import Image\n",
        "import os\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "\n",
        "#@markdown ### üñºÔ∏è Reducir tama√±o de im√°genes\n",
        "#@markdown Esto convertir√° todas las im√°genes en la carpeta del proyecto a jpeg, reduciendo el tama√±o sin afectar mucho la calidad. Esto tambi√©n puede solucionar algunos errores.\n",
        "location = images_folder\n",
        "\n",
        "for dir in [d[0] for d in os.walk(location)]:\n",
        "    os.chdir(dir)\n",
        "    converted = False\n",
        "    for file_name in list(os.listdir(\".\")):\n",
        "        try:\n",
        "            # Convert png to jpeg\n",
        "            if file_name.endswith(\".png\"):\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                    converted = True\n",
        "                im = Image.open(file_name)\n",
        "                im = im.convert(\"RGB\")\n",
        "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
        "                im.save(new_file_name, quality=95)\n",
        "                os.remove(file_name)\n",
        "                file_name = new_file_name\n",
        "            # Resize large jpegs\n",
        "            if file_name.endswith((\".jpeg\", \".jpg\")) and os.path.getsize(file_name) > 2000000:\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                    converted = True\n",
        "                im = Image.open(file_name)\n",
        "                im = im.resize((int(im.width/2), int(im.height/2)))\n",
        "                im.save(file_name, quality=95)\n",
        "            # Rename jpg to jpeg\n",
        "            if file_name.endswith(\".jpg\"):\n",
        "                if not converted:\n",
        "                    print(f\"Converting {dir}\")\n",
        "                new_file_name = os.path.splitext(file_name)[0] + \".jpeg\"\n",
        "                os.rename(file_name, new_file_name)\n",
        "        except Exception as e:\n",
        "            print(f\"An error occurred while processing {file_name}: {e}\")\n",
        "    if converted:\n",
        "        print(f\"Converted {dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "l0tzRu6xBqj9"
      },
      "outputs": [],
      "source": [
        "if \"step1_installed_flag\" not in globals():\n",
        "  raise Exception(\"Por favor usa el paso 1 primero.\")\n",
        "\n",
        "#@markdown ### üöÆ Limpiar carpeta\n",
        "#@markdown Cuidado, borra todos los archivos que no sean im√°genes de la carpeta del proyecto.\n",
        "\n",
        "!find {images_folder} -type f ! \\( -name '*.png' -o -name '*.jpg' -o -name '*.jpeg' \\) -delete"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}